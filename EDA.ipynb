{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset in this project which is provided by Kaggle, was generated from a deep learning model trained on the Bank Marketing Dataset dataset (old version named \"bank-full.csv\").\n",
    "\n",
    "### About the original dataset\n",
    "Data was collected from May 2008 to November 2010 and donated on 2/13/2012\n",
    "\n",
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The marketing campaigns were based on phone calls.\n",
    "\n",
    "### Goal\n",
    "The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "### Variable Explaination Obtained from UCI\n",
    "\n",
    "**age**\n",
    "\n",
    "**job**\n",
    "\n",
    "**marital** note: 'divorced' means divorced or widowed\n",
    "\n",
    "**education**\n",
    "\n",
    "**default** has credit in default?\n",
    "\n",
    "**balance** average yearly balance\n",
    "\n",
    "**housing** has housing loan?\n",
    "\n",
    "**loan** has personal loan?\n",
    "\n",
    "**contact**\n",
    "\n",
    "**day** last contact day of the month\n",
    "\n",
    "**month** last contact month of year\n",
    "\n",
    "**duration** last contact duration, in seconds. Important note: **this attribute highly affects the output target** (e.g., if duration=0 then y='no'). **Yet, the duration is not known before a call is performed**. Also, after the end of the call y is obviously known. Thus, this input should **only be included for benchmark** purposes and should be **discarded if the intention is to have a realistic predictive model**.\n",
    "\n",
    "**campaign** number of contacts performed during this campaign and for this client (includes last contact)\t\n",
    "\n",
    "**pdays** number of days that passed by after the client was last contacted from a previous campaign (numeric; -1 means client was not previously contacted)\n",
    "\n",
    "**previous** number of contacts performed before this campaign and for this client\t\n",
    "\n",
    "**poutcome** outcome of the previous marketing campaign (UCI's categorical: 'failure',**'nonexistent'**,'success'; Kaggle's categorical: **\"unknown\",\"other\"**,\"failure\",\"success\")\n",
    "\n",
    "**y** has the client subscribed a term deposit?\t(1 = Yes, 0 = No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chi2_contingency, ks_2samp\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.duplicated().any())\n",
    "print(test.duplicated().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['job', 'marital', 'education', 'default', 'housing', \n",
    "                    'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and percentage\n",
    "y_counts = train['y'].value_counts()\n",
    "y_percent = (y_counts / len(train) * 100).round(1)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "bars = plt.bar(y_counts.index.astype(str), y_counts.values, color=['#FF6F61', '#6BB5FF'])\n",
    "\n",
    "# Add labels on top of bars\n",
    "for bar, percent in zip(bars, y_percent):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + len(train)*0.005,\n",
    "             f'{bar.get_height():,} ({percent}%)',\n",
    "             ha='center', fontsize=12, weight='bold')\n",
    "\n",
    "plt.title('Term Deposit Subscription', fontsize=14, weight='bold')\n",
    "plt.xlabel('Subscription (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Number of Clients')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatter function: 1000 → 1k\n",
    "def format_thousands(x, pos):\n",
    "    if x >= 1000:\n",
    "        return f'{int(x/1000)}k'\n",
    "    return int(x)\n",
    "\n",
    "formatter = FuncFormatter(format_thousands)\n",
    "month_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun',\n",
    "               'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "# Set up grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "total_count = len(train)\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    # Choose specific order for 'month', otherwise use value_counts\n",
    "    if col == 'month':\n",
    "        order = month_order\n",
    "    else:\n",
    "        order = train[col].value_counts().index\n",
    "\n",
    "    ax = axes[i]\n",
    "    sns.countplot(data=train, y=col, order=order, ax=ax)\n",
    "    ax.set_title(f\"{col} Distribution\")\n",
    "    ax.tick_params(axis='y', labelrotation=0)\n",
    "    ax.xaxis.set_major_formatter(formatter)  # Apply 1k formatting\n",
    "\n",
    "    # Add percentage labels on each bar\n",
    "    for patch in ax.patches:\n",
    "        width = patch.get_width()\n",
    "        pct = (width / total_count) * 100\n",
    "        ax.text(width + 0.02 * total_count,\n",
    "                patch.get_y() + patch.get_height() / 2,\n",
    "                f'{pct:.1f}%',  # one decimal place\n",
    "                va='center')\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(len(categorical_cols), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(18, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    idx = i * 2\n",
    "    sns.histplot(data=train, x=col, kde=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f\"{col} Histogram\")\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    sns.boxplot(data=train, x=col, ax=axes[idx + 1])\n",
    "    axes[idx + 1].set_title(f\"{col} Boxplot\")\n",
    "    axes[idx + 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hide unused plots if any\n",
    "for j in range(2 * len(numeric_cols), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Drift Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_drift(train, test, categorical_cols, numeric_cols, alpha=0.05):\n",
    "    drift = {}\n",
    "\n",
    "    # Categorical: Chi-Square test\n",
    "    for col in categorical_cols:\n",
    "        table = pd.concat([train[col].value_counts(), test[col].value_counts()],\n",
    "                          axis=1, keys=['Train', 'Test']).fillna(0)\n",
    "        drift[col] = 1.0 if table.shape[0] == 1 else chi2_contingency(table)[1]\n",
    "\n",
    "    # Numeric: KS test\n",
    "    for col in numeric_cols:\n",
    "        t, v = train[col].dropna(), test[col].dropna()\n",
    "        drift[col] = np.nan if t.empty or v.empty else ks_2samp(t, v)[1]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(drift, orient='index', columns=['p_value'])\n",
    "    df['drift'] = np.where(df['p_value'] < alpha, 'Yes', 'No')\n",
    "    return df.sort_values('p_value', ascending=False)\n",
    "\n",
    "# Example usage\n",
    "drift_df = detect_drift(train, test, categorical_cols, numeric_cols)\n",
    "print(drift_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "total_rows = len(df)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Compute relative frequency (as a percentage between 0 and 1)\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[col + '_pct'] = df[col].map(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = sorted(['contact_pct', 'default_pct', 'education_pct', 'job_pct',\n",
    "                           'loan_pct', 'marital_pct', 'month_pct', 'poutcome_pct','housing_pct'])\n",
    "numerical_cols = sorted(['age', 'balance', 'campaign', 'day', 'duration', 'pdays', 'previous'])\n",
    "target_col = ['y']\n",
    "\n",
    "# Reorder columns\n",
    "ordered_cols = categorical_cols + numerical_cols + target_col\n",
    "df_ordered = df[ordered_cols]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = df_ordered.corr()\n",
    "\n",
    "# Mask small correlations\n",
    "mask = np.abs(corr) <= 0.1\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", mask=mask, cbar_kws={'label': 'Correlation'})\n",
    "\n",
    "# Draw group separators\n",
    "cat_end = len(categorical_cols)\n",
    "num_end = len(categorical_cols) + len(numerical_cols)\n",
    "\n",
    "plt.axhline(cat_end, color='black', linestyle='--', linewidth=1)\n",
    "plt.axhline(num_end, color='black', linestyle='--', linewidth=1)\n",
    "plt.axvline(cat_end, color='black', linestyle='--', linewidth=1)\n",
    "plt.axvline(num_end, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "# Add colored background for groups using rectangles\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# Categorical group background (light blue)\n",
    "ax.add_patch(Rectangle((0, 0), cat_end, cat_end, fill=True, color='lightblue', alpha=0.3, zorder=-1))\n",
    "ax.add_patch(Rectangle((0, cat_end), cat_end, len(ordered_cols)-cat_end, fill=True, color='lightblue', alpha=0.3, zorder=-1))\n",
    "\n",
    "# Numerical group background (light green)\n",
    "ax.add_patch(Rectangle((cat_end, 0), len(numerical_cols), num_end, fill=True, color='lightgray', alpha=0.3, zorder=-1))\n",
    "ax.add_patch(Rectangle((cat_end, num_end), len(numerical_cols), len(target_col), fill=True, color='lightgray', alpha=0.3, zorder=-1))\n",
    "\n",
    "# Target background (light pink)\n",
    "ax.add_patch(Rectangle((num_end, 0), len(target_col), len(ordered_cols), fill=True, color='lightpink', alpha=0.3, zorder=-1))\n",
    "\n",
    "# Add group labels on top\n",
    "plt.text(cat_end/2, len(ordered_cols)+3, \"Categorical\", ha='center', fontsize=12, color='blue', fontweight='bold')\n",
    "plt.text(cat_end + len(numerical_cols)/2, len(ordered_cols)+3, \"Numerical\", ha='center', fontsize=12, color='gray', fontweight='bold')\n",
    "plt.text(num_end + 0.5, len(ordered_cols)+3, \"Target\", ha='center', fontsize=12, color='darkred', fontweight='bold')\n",
    "\n",
    "# After drawing group labels on top\n",
    "# Add group labels on the left\n",
    "plt.text(-2.5, cat_end/2, \"Categorical\", va='center', ha='center', fontsize=12, color='blue', fontweight='bold', rotation=90)\n",
    "plt.text(-2.5, cat_end + len(numerical_cols)/2, \"Numerical\", va='center', ha='center', fontsize=12, color='gray', fontweight='bold', rotation=90)\n",
    "plt.text(-2.5, num_end + len(target_col)/2, \"Target\", va='center', ha='center', fontsize=12, color='darkred', fontweight='bold', rotation=90)\n",
    "\n",
    "\n",
    "plt.title(\"Correlation Heatmap (>0.1 highlighted)\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown contacts are not strong predictors of subscription outcomes. However, they are strongly associated with brand-new customers.\n",
    "\n",
    "Most new customers ('previous' == 0 and pdays == -1) was contacted by unknown type. This \"unknown\" type appear mainly in May and June with a significant number of phone call, which is unusual. By checking the duration of each contact (in seconds), it can be sure that the contact was actually made and recorded and \"unknown\" does not mean no contact.\n",
    "\n",
    "There is posibility that there was campaigns during May-June targeting new customer and the system haven't recorded their primary contact method yet.\n",
    "\n",
    "Action: Keep the column. Apply label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total rows with contact = unknown\n",
    "total_unknown = df[df['contact'] == 'unknown'].shape[0]\n",
    "\n",
    "# Rows that are brand new AND contact = unknown\n",
    "brand_new_unknown = df[\n",
    "    (df['contact'] == 'unknown') &\n",
    "    (df['previous'] == 0) &\n",
    "    (df['pdays'] == -1)\n",
    "].shape[0]\n",
    "\n",
    "# Proportion\n",
    "proportion = brand_new_unknown / total_unknown if total_unknown > 0 else 0\n",
    "\n",
    "print(\"Total with contact=unknown:\", total_unknown)\n",
    "print(\"New customer with contact=unknown:\", brand_new_unknown)\n",
    "print(f\"Proportion: {proportion:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of each contact type per month\n",
    "contact_counts = df.groupby(['month','contact']).size().unstack(fill_value=0).reindex(month_order)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "contact_counts.plot(\n",
    "    kind='bar', \n",
    "    stacked=True, \n",
    "    figsize=(12,5), \n",
    "    color=['skyblue','lightgreen','lightcoral'], \n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title('Number of Contacts per Month by Contact Type')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Contacts')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Contact Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary column for unknown contact\n",
    "df['contact_unknown'] = (df['contact'] == 'unknown').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_ordered = df[['contact_pct','contact_unknown','y']]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr = df_ordered.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar_kws={'label': 'Correlation'})\n",
    "\n",
    "# Draw group separators\n",
    "cat_end = len(categorical_cols)\n",
    "num_end = len(categorical_cols) + len(numerical_cols)\n",
    "\n",
    "plt.title(\"Correlation Heatmap (>0.1 highlighted)\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter brand-new customers ---\n",
    "brand_new_unknown = df[(df['previous'] == 0) & \n",
    "               (df['pdays'] == -1) & \n",
    "               (df['poutcome'] == 'unknown') &\n",
    "               (df['contact'] == 'unknown')].copy()\n",
    "\n",
    "# --- Define duration bins (seconds) ---\n",
    "bins = [0, 30, 60, 120, 300, float('inf')]\n",
    "labels = ['0-30', '30-60', '60-120', '120-300', '>300']\n",
    "\n",
    "# --- Create duration group column ---\n",
    "brand_new_unknown['duration_group'] = pd.cut(brand_new_unknown['duration'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# --- Month order ---\n",
    "month_order = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "\n",
    "# --- Group by month and duration group ---\n",
    "duration_counts = (\n",
    "    brand_new_unknown.groupby(['month', 'duration_group'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reindex(month_order)\n",
    ")\n",
    "\n",
    "# --- Plot stacked horizontal bar chart ---\n",
    "duration_counts.plot(\n",
    "    kind='barh',\n",
    "    stacked=True,\n",
    "    figsize=(12, 6),\n",
    "    colormap='Paired'\n",
    ")\n",
    "\n",
    "plt.title('Duration Distribution of Last Call for Brand-New Customers by Month', fontsize=14)\n",
    "plt.xlabel('Number of Customers', fontsize=12)\n",
    "plt.ylabel('Month', fontsize=12)\n",
    "plt.legend(title='Duration (seconds)', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"default\" column carry extreme imbalance classes with ~98.3% \"No\" and only 1.7% \"Yes\". \n",
    "\n",
    "Heatmap shows weak/no correlation with the target y and with other predictors.\n",
    "\n",
    "Action: drop \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap shows weak correlation with the target y.\n",
    "\n",
    "\"education\" has higher correlation with \"age\" and \"job\". However this only explain who subscribe, not an indicator for subscription rate.\n",
    "\n",
    "Action: Apply label encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap of balance by job and age group shows that people aged 65+ have substantially higher balances than other age groups, regardless of job title.\n",
    "\n",
    "Action: Create new column \"age_group\" to reduce dimension of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age bins\n",
    "age_bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "age_labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median balance pivot by age group\n",
    "pivot_agegroup = df.pivot_table(\n",
    "    index='job',\n",
    "    columns='age_group',\n",
    "    values='balance',\n",
    "    aggfunc = 'median',\n",
    "    ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex pivot\n",
    "pivot_filled = pivot_agegroup.reindex([\n",
    "    'management', 'blue-collar', 'technician', 'admin.', 'services',\n",
    "    'retired', 'self-employed', 'entrepreneur', 'unemployed', 'housemaid',\n",
    "    'student', 'unknown'\n",
    "])\n",
    "\n",
    "# Create figure and axes if not already defined\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 8))  # single subplot\n",
    "\n",
    "# Left Heatmap: Median Balance by Job and Age Group\n",
    "sns.heatmap(\n",
    "    pivot_filled,\n",
    "    annot=pivot_filled.applymap(lambda x: f\"{x:,.0f}\"),\n",
    "    fmt=\"\", \n",
    "    cmap=\"YlGnBu\",\n",
    "    cbar_kws={'label': 'Median Balance (€)'},\n",
    "    ax=axes\n",
    ")\n",
    "\n",
    "axes.set_title('Median Balance by Job and Age Group')\n",
    "axes.set_xlabel('Age Group')\n",
    "axes.set_ylabel('Job')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of job, age and balance indicates that it's possible to group jobs into different clusters that are similar.\n",
    "\n",
    "Action: Create \"job_group\" columns with 4 group names: Senior (management, retired), Student (student), Worker (admin, blue-collar, entrepreneur, housemaid, technician), and Independent (unemployed, unknown, self-employed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median balance pivot by age group\n",
    "pivot = df.pivot_table(\n",
    "    index='job',\n",
    "    columns='age',\n",
    "    values='balance').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(pivot_agegroup)\n",
    "\n",
    "# PCA to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create DataFrame with PCA coordinates\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'], index=pivot_agegroup.index)\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of clusters\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "pca_df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x='PC1', y='PC2',\n",
    "    data=pca_df,\n",
    "    hue='Cluster',\n",
    "    palette='Set2',\n",
    "    s=200\n",
    ")\n",
    "\n",
    "# Add job labels\n",
    "for job in pca_df.index:\n",
    "    plt.text(\n",
    "        x=pca_df.loc[job, 'PC1'] + 0.05,\n",
    "        y=pca_df.loc[job, 'PC2'] + 0.05,\n",
    "        s=job,\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "plt.title('PCA of Jobs Based on Age Group and Balance')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### marital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"marital\" has weak correlation to target y, which mean \"marital\" alone doesn't strongly predict subscription.\n",
    "\n",
    "\"marital\" has slightly higher correlation to only one variable \"age\", that's expected.\n",
    "\n",
    "Action: Keep this column, apply label encoding. Consider drop this column for dimension reduction purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='marital', y='age', data=df, palette='Set2')\n",
    "plt.title('Age Distribution by Marital Status')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High subscription rate months likes Mar (57%), Sep (53%), Dec (51%), Oct (49%) are likely strategically targeted campaigns, e.g., quarter-end promotions, special banking offers, or months when clients are more likely to respond.\n",
    "\n",
    "Low subscription months coincide with summer or holiday periods, e.g., May–August in many countries, when clients may be on vacation or less responsive.\n",
    "\n",
    "Inverse relationship between number of calls and subscription rate: High subscription rate months with few calls. Low subscription rate months with many calls\n",
    "\n",
    "Action: Keep the month as it is. Apply label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "subscription_rate = df.groupby('month')['y'].mean().reindex(month_order)\n",
    "num_calls = df['month'].value_counts().reindex(month_order)\n",
    "\n",
    "# Gradient for subscription rate\n",
    "norm = (subscription_rate - subscription_rate.min()) / (subscription_rate.max() - subscription_rate.min())\n",
    "colors = sns.color_palette(\"Blues\", n_colors=len(subscription_rate))\n",
    "bar_colors = [colors[int(v*(len(subscription_rate)-1))] for v in norm]\n",
    "\n",
    "# X-axis numeric for months\n",
    "x = np.arange(len(month_order))\n",
    "\n",
    "# Smooth curve for number of calls (normalize to 0–1 for visualization)\n",
    "num_calls_norm = (num_calls - num_calls.min()) / (num_calls.max() - num_calls.min())\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "spl = make_interp_spline(x, num_calls_norm.values, k=3)\n",
    "num_calls_smooth = spl(x_smooth)\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "\n",
    "# 1. Area plot for normalized number of calls\n",
    "ax1.fill_between(x_smooth, num_calls_smooth, color='lightgreen', alpha=0.4, zorder=1)\n",
    "ax1.plot(x_smooth, num_calls_smooth, color='lightgreen', linewidth=0.2, zorder=1)\n",
    "\n",
    "# 2. Bars for subscription rate (in front)\n",
    "ax1.bar(\n",
    "    x, \n",
    "    subscription_rate.values, \n",
    "    color=bar_colors, \n",
    "    width=0.6, \n",
    "    alpha=0.6,\n",
    "    zorder=2, \n",
    "    edgecolor='black',   \n",
    "    linewidth=1.2        \n",
    ")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(month_order)\n",
    "ax1.set_ylim(0, 1.2) \n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Subscription Rate (y=1)')\n",
    "\n",
    "plt.title('Monthly Subscription Rate (Bars) and Number of Calls (Normalized Area Behind)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call distribution varies month by month:\n",
    "\n",
    "Some months focus heavily on clients with housing loans (e.g., May, Jun, Jul). It could be the result of a compaign that targeted new customer with housing loan.\n",
    "\n",
    "Action: Keep housing, apply label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure month order\n",
    "month_order = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "\n",
    "# Aggregate housing counts per month\n",
    "housing_month = df.groupby(['month','housing']).size().unstack(fill_value=0).reindex(month_order)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "housing_month.plot(\n",
    "    kind='bar', \n",
    "    stacked=True, \n",
    "    figsize=(12,5),\n",
    "    color=['lightcoral', 'skyblue'],  # no vs yes\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title('Number of Clients with/without Housing Loan by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Clients')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Housing Loan')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal loan have low correlation to all variables, including target 'y'. \n",
    "\n",
    "Subscription rate of clients with no personal loan and no housing loan are higher than the others.\n",
    "\n",
    "Action: Keep the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute subscription rate by housing and loan\n",
    "pivot_rate = df.groupby(['housing', 'loan'])['y'].mean().unstack(fill_value=0)\n",
    "\n",
    "print(pivot_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loan_counts(sub_value):\n",
    "    subset = df[df['y']==sub_value]\n",
    "    return [\n",
    "        ((subset['loan']=='no') & (subset['housing']=='no')).sum(),  # No Loan\n",
    "        ((subset['loan']=='yes') & (subset['housing']=='no')).sum(), # Personal Loan\n",
    "        ((subset['loan']=='no') & (subset['housing']=='yes')).sum()  # Housing Loan\n",
    "    ]\n",
    "\n",
    "# Counts for each subscription status\n",
    "counts_no = np.array(loan_counts(0))\n",
    "counts_yes = np.array(loan_counts(1))\n",
    "\n",
    "labels = ['No Loan','Personal Loan','Housing Loan']\n",
    "colors = ['lightgray','lightcoral','skyblue']\n",
    "\n",
    "# Y positions\n",
    "y = [0, 1]  # 0: Not Subscribed, 1: Subscribed\n",
    "bar_height = 0.6\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "\n",
    "# Stacked horizontal bars using cumulative sum\n",
    "ax.barh(y[0], counts_no, left=np.cumsum(np.insert(counts_no, 0, 0))[:-1], color=colors, edgecolor='black', height=bar_height)\n",
    "ax.barh(y[1], counts_yes, left=np.cumsum(np.insert(counts_yes, 0, 0))[:-1], color=colors, edgecolor='black', height=bar_height)\n",
    "\n",
    "# Labels and legend\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(['Not Subscribed','Subscribed'])\n",
    "ax.set_xlabel('Number of Clients')\n",
    "ax.set_title('Subscription by Loan/Housing Status (Counts)')\n",
    "patches = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(labels))]\n",
    "ax.legend(handles=patches, title='Loan/Housing Type')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### poutcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From heatmap analysis, poutcome_pct has high correlation with pdays (-0.89) and previous (-0.66).\n",
    "\n",
    "Chi-square Test prove that poutcome and y are dependent. However, the correlation between poutcome and y are weak (-0.17).\n",
    "\n",
    "By calculating the subscription rate (y = 1) for each poutcome category, \"success\" is strongly predictive (y=1 rate 0.76), while unknown, failure, and other are weak.\n",
    "\n",
    "Most of the previous outcome of customer with 'previous' == 0 and pdays == -1 are \"unknown\" because they was not contacted or attended in any campaign before. Thus, those customer can be grouped as \"new customer\".\n",
    "\n",
    "Action: Keep poutcome. Apply label encoding for tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_new = df[(df['previous'] == 0) & \n",
    "               (df['pdays'] == -1)].copy()\n",
    "\n",
    "# Check unique values of poutcome for these rows\n",
    "unique_poutcome = brand_new['poutcome'].unique()\n",
    "print(\"Unique 'poutcome' values for previous=0 and pdays=-1:\")\n",
    "print(unique_poutcome)\n",
    "\n",
    "# Count of each value\n",
    "poutcome_counts = brand_new['poutcome'].value_counts()\n",
    "print(\"\\nCounts of 'poutcome' for previous=0 and pdays=-1:\")\n",
    "print(poutcome_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define old/returning customers\n",
    "old_customer = df[~df.index.isin(brand_new.index)]\n",
    "\n",
    "# Count per month\n",
    "month_order = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "\n",
    "brand_new_count = brand_new['month'].str.lower().value_counts().reindex(month_order, fill_value=0)\n",
    "old_customer_count = old_customer['month'].str.lower().value_counts().reindex(month_order, fill_value=0)\n",
    "\n",
    "# Combine into one DataFrame\n",
    "customer_counts = pd.DataFrame({\n",
    "    'Brand New': brand_new_count,\n",
    "    'Returning': old_customer_count\n",
    "})\n",
    "\n",
    "# Plot grouped bar chart\n",
    "customer_counts.plot(\n",
    "    kind='bar',\n",
    "    figsize=(12,6),\n",
    "    color=['skyblue','lightgreen']\n",
    ")\n",
    "plt.title('Brand New vs Returning Customers by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Customer Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chi-square test ---\n",
    "# Create contingency table\n",
    "contingency_table = pd.crosstab(df['poutcome'], df['y'])\n",
    "\n",
    "# Perform Chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"\\nChi-square statistic: {chi2:.3f}\")\n",
    "print(f\"P-value: {p:.3f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(\"Expected frequencies:\\n\", expected)\n",
    "\n",
    "# Interpretation\n",
    "if p < 0.05:\n",
    "    print(\"\\nResult: Reject null hypothesis — poutcome and y are dependent.\")\n",
    "else:\n",
    "    print(\"\\nResult: Fail to reject null hypothesis — poutcome and y may be independent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('poutcome')['y'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"balance\" has a weak correlation (0.11) with \"duration\", which is a leakage.\n",
    "\n",
    "\"balance\" has a weak correlation (0.12) with \"y\".\n",
    "\n",
    "Action: Keep balance as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"campaign\" has a weak correlation (0.18) with \"day\" and not correlate with \"y\". \n",
    "\n",
    "Action: Keep as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Count number of clients per campaign number grouped by subscription outcome\n",
    "campaign_counts = df.groupby(['campaign', 'y']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot stacked bar\n",
    "campaign_counts.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(12,6),\n",
    "    color=['#ff9999', '#99ccff'],\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.title(\"Subscription Outcome by Number of Contacts in Current Campaign\", fontsize=14)\n",
    "plt.xlabel(\"Number of Contacts (campaign)\")\n",
    "plt.ylabel(\"Number of Clients\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Subscription\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action: Keep day as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define months in order\n",
    "months_order = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "\n",
    "# Create subplots for all 12 months (3 rows × 4 columns)\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, month in enumerate(months_order):\n",
    "    # Filter data for the current month\n",
    "    month_data = brand_new[brand_new['month'].str.lower() == month]\n",
    "\n",
    "    # Group by day and contact type\n",
    "    daily_counts = (\n",
    "        month_data.groupby(['day', 'contact'])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # Plot stacked bar for that month\n",
    "    daily_counts.plot(\n",
    "        kind='bar',\n",
    "        stacked=True,\n",
    "        ax=axes[i],\n",
    "        color=['#1f77b4', '#ff7f0e', '#2ca02c']  # unknown, cellular, telephone\n",
    "    )\n",
    "\n",
    "    axes[i].set_title(f'{month.capitalize()}', fontsize=14)\n",
    "    axes[i].set_xlabel('Day of Month')\n",
    "    axes[i].set_ylabel('Number of Calls')\n",
    "    axes[i].tick_params(axis='x', rotation=0)\n",
    "    axes[i].grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add a single legend for the whole figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, title='Contact Type', loc='upper center', ncol=3, fontsize=12)\n",
    "\n",
    "plt.suptitle('Number of Calls per Day by Contact Type (Brand-New Customers)', fontsize=18, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the variable explaination, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. \n",
    "\n",
    "Action: Keep \"duration\" column for benchmarking model only, remove it for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_binned'] = pd.cut(df['duration'], \n",
    "                               bins=[0, 60, 120, 180, 300, 600, df['duration'].max()],\n",
    "                               labels=['0-1min', '1-2min', '2-3min', '3-5min', '5-10min', '10min+'])\n",
    "\n",
    "rate_per_bin = df.groupby('duration_binned')['y'].mean()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=rate_per_bin.index, y=rate_per_bin.values, color='skyblue')\n",
    "plt.title('Higher Call Duration Leads to Higher Subscription Rate')\n",
    "plt.xlabel('Call Duration (Binned)')\n",
    "plt.ylabel('Subscription Rate (y=1)')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(rate_per_bin.values):\n",
    "    plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation of \"pdays\" and \"previous\" are high at 0.56. If a client was never contacted before (previous = 0), then pdays will usually be -1 (meaning \"not contacted\"). \n",
    "\n",
    "Clients contacted recently (31–90 days) have the highest subscription rate. Those never contacted or contacted very long ago have low subscription rates.\n",
    "\n",
    "Action: Create a new feature \"was_contact_before\" where 0 = No, 1 = Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 with NaN for distribution/bins\n",
    "df['pdays_clean'] = df['pdays'].replace(-1, pd.NA)\n",
    "\n",
    "# Binning pdays into ranges\n",
    "bins = [-1, 0, 30, 90, 180, 365, df['pdays_clean'].max()]\n",
    "labels = ['not_contacted', '0-30', '31-90', '91-180', '181-365', '366+']\n",
    "df['pdays_binned'] = pd.cut(df['pdays'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Check proportion of y=1 per bin\n",
    "proportion_per_bin = df.groupby('pdays_binned')['y'].mean()\n",
    "print(proportion_per_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"previous\" has strong correlation to pdays (0.56) and poutcome (-0.66) but weak correlation to target 'y'. \n",
    "\n",
    "\"previous\" together with \"pdays\" indicate who is the new customer that was not contacted before.\n",
    "\n",
    "Action: Keep previous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Pipeline\n",
    "\n",
    "class BankPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Age bins\n",
    "        self.age_bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "        self.age_labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "        \n",
    "        # Job clustering\n",
    "        self.pca_clusters = {\n",
    "            'admin.': 2, 'blue-collar': 2, 'entrepreneur': 2, 'housemaid': 2,\n",
    "            'management': 0, 'retired': 0, 'self-employed': 3, 'services': 2,\n",
    "            'student': 1, 'technician': 2, 'unemployed': 3, 'unknown': 3\n",
    "        }\n",
    "        self.cluster_mapping = {0:'senior', 1:'student', 2:'worker', 3:'independent'}\n",
    "        self.job_to_group = {job: self.cluster_mapping[cluster] for job, cluster in self.pca_clusters.items()}\n",
    "        \n",
    "        # Columns to encode\n",
    "        self.categorical_cols = ['poutcome', 'contact', 'education', 'marital', 'month',\n",
    "                                 'housing','loan','job_group','age_group']\n",
    "        self.le_dict = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # --- Create derived columns first ---\n",
    "        X['age_group'] = pd.cut(X['age'], bins=self.age_bins, labels=self.age_labels)\n",
    "        X['job_group'] = X['job'].map(self.job_to_group)\n",
    "        \n",
    "        # Ensure all categorical columns have 'Unknown' category\n",
    "        for col in self.categorical_cols:\n",
    "            X[col] = X[col].astype(str).fillna('Unknown')\n",
    "        \n",
    "        # --- Fit LabelEncoders ---\n",
    "        for col in self.categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[col])\n",
    "            self.le_dict[col] = le\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # --- Create derived columns ---\n",
    "        X['age_group'] = pd.cut(X['age'], bins=self.age_bins, labels=self.age_labels)\n",
    "        X['job_group'] = X['job'].map(self.job_to_group)\n",
    "        X['was_contacted_before'] = X['pdays'].apply(lambda x: 0 if x == -1 else 1)\n",
    "        \n",
    "        # Drop unused columns\n",
    "        drop_cols = ['id','job','age','default','duration']\n",
    "        X = X.drop(columns=[c for c in drop_cols if c in X.columns])\n",
    "        \n",
    "        return X\n",
    "\n",
    "# --- Create pipeline ---\n",
    "pipeline2 = Pipeline([\n",
    "    ('preprocessor', BankPreprocessor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pipeline2.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding Pipeline\n",
    "class BankPreprocessorLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Columns to encode\n",
    "        self.categorical_cols = ['marital','education','housing','loan','contact','month','poutcome','age_group','job_group']\n",
    "        self.le_dict = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Ensure all categorical columns have 'Unknown' category\n",
    "        for col in self.categorical_cols:\n",
    "            X[col] = X[col].astype(str).fillna('Unknown')\n",
    "        \n",
    "        # Fit LabelEncoders\n",
    "        for col in self.categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[col].unique())\n",
    "            self.le_dict[col] = le\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Fill missing and unseen values with 'Unknown'\n",
    "        for col in self.categorical_cols:\n",
    "            X[col] = X[col].astype(str)\n",
    "            le = self.le_dict[col]\n",
    "            X[col] = X[col].apply(lambda x: x if x in le.classes_ else 'Unknown')\n",
    "            X[col] = le.transform(X[col])\n",
    "        \n",
    "        return X\n",
    "\n",
    "# --- Create pipeline ---\n",
    "pipeline3 = Pipeline([\n",
    "    ('preprocessor', BankPreprocessorLabelEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pipeline3.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor3 = pipeline3.named_steps['preprocessor']\n",
    "\n",
    "for col, le in preprocessor3.le_dict.items():\n",
    "    mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "    print(f\"Column: {col}\")\n",
    "    for label, number in mapping.items():\n",
    "        print(f\"  {number} -> {label}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested preprocessing pipeline for training model\n",
    "preprocessor_pipeline = Pipeline([\n",
    "    ('bank_preprocessor', BankPreprocessor()),          \n",
    "    ('label_encoder', BankPreprocessorLabelEncoder())   \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine \"age\" into age group\n",
    "\n",
    "# age_bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "# age_labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "\n",
    "# train['age_group'] = pd.cut(train['age'], bins=age_bins, labels=age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary feature: was_contacted_before ---\n",
    "# train['was_contacted_before'] = train['pdays'].apply(lambda x: 0 if x == -1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine job into job group\n",
    "# pca_clusters = {\n",
    "#     'admin.': 2,\n",
    "#     'blue-collar': 2,\n",
    "#     'entrepreneur': 2,\n",
    "#     'housemaid': 2,\n",
    "#     'management': 0,\n",
    "#     'retired': 0,\n",
    "#     'self-employed': 3,\n",
    "#     'services': 2,\n",
    "#     'student': 1,\n",
    "#     'technician': 2,\n",
    "#     'unemployed': 3,\n",
    "#     'unknown': 3\n",
    "# }\n",
    "\n",
    "# cluster_mapping = {\n",
    "#     0: 'Senior',\n",
    "#     1: 'Student',\n",
    "#     2: 'Worker',\n",
    "#     3: 'Independent'\n",
    "# }\n",
    "\n",
    "# # Map job to job group\n",
    "# job_to_group = {job: cluster_mapping[cluster] for job, cluster in pca_clusters.items()}\n",
    "\n",
    "# # Create new column in dataset\n",
    "# train['job_group'] = train['job'].map(job_to_group)\n",
    "\n",
    "# # Check results\n",
    "# train[['job', 'job_group']].head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # poutcome\n",
    "# le = LabelEncoder()\n",
    "# categorical_cols = ['poutcome', 'contact', 'education', 'marital', 'month','housing','loan','job_group','age_group']\n",
    "\n",
    "# # Apply LabelEncoder to each column\n",
    "# for col in categorical_cols:\n",
    "#     train[col + '_encoded'] = le.fit_transform(train[col])\n",
    "\n",
    "# # Optional: check the first few rows\n",
    "# train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create binary feature: was_contacted_before ---\n",
    "# train['was_contacted_before'] = train['pdays'].apply(lambda x: 0 if x == -1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop(columns=['id','poutcome', 'contact', 'education', 'marital', 'month','housing','loan','job','age','age_group','job_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop(columns=['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split X and y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"y\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"y\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model_1 = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1 (\"Yes\")\n",
    "y_probs = model_1.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification report, convert probabilities with threshold 0.5\n",
    "y_pred = (y_probs >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(class_weight='balanced',random_state=11)\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1 (\"Yes\")\n",
    "y_probs_rf = model_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_rf):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification report, convert probabilities with threshold 0.5\n",
    "y_pred_3 = (y_probs_rf >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "pos = sum(y_train == 1)\n",
    "neg = sum(y_train == 0)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# Create and train the model\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1 (\"Yes\")\n",
    "y_probs_xgb = model_xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_xgb):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification report, convert probabilities with threshold 0.5\n",
    "y_pred_4 = (y_probs_xgb >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    scale_pos_weight=scale_pos_weight,  # or use is_unbalance=True\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1 (\"Yes\")\n",
    "y_probs_lgb = model_lgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_lgb):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification report, convert probabilities with threshold 0.5\n",
    "y_pred_5 = (y_probs_lgb >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tunning - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# --- Logistic Regression with class weights ---\n",
    "lr = LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # automatically adjust weights for minority class\n",
    ")\n",
    "\n",
    "# --- Hyperparameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],   # inverse regularization strength\n",
    "    'penalty': ['l1', 'l2']         # regularization type\n",
    "}\n",
    "\n",
    "# --- Grid search ---\n",
    "grid = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # optimize for AUC\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# --- Best parameters and score ---\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV AUC:\", grid.best_score_)\n",
    "\n",
    "# --- Evaluate on test set ---\n",
    "y_pred = grid.predict(X_test)\n",
    "y_proba = grid.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_1 = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_lr_1 = model_lr_1.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_lr_1):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_1 = (y_probs_lr_1 >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_lr_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_1 = RandomForestClassifier(class_weight='balanced',random_state=11)\n",
    "model_rf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_rf_1 = model_rf_1.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_rf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_rf_1):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_1 = (y_probs_rf_1 >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_rf_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate imbalance ratio\n",
    "pos = sum(y_train == 1)\n",
    "neg = sum(y_train == 0)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# Create and train the model\n",
    "model_xgb_1 = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model_xgb_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_xgb_1 = model_xgb_1.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_xgb_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_xgb_1):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_1 = (y_probs_xgb_1 >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_xgb_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LightBGM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_1 = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    scale_pos_weight=scale_pos_weight,  # or use is_unbalance=True\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "model_lgb_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_lgb_1 = model_lgb_1.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_lgb_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC-ROC: {roc_auc_score(y_test, y_probs_lgb_1):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb_1 = (y_probs_lgb_1 >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_lgb_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode = test.drop(columns=[\"id\"])\n",
    "test_encode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical encoding to keep day-month cycles\n",
    "month_map = {\n",
    "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "    'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "}\n",
    "\n",
    "test_encode['month_num'] = test_encode['month'].map(month_map)\n",
    "\n",
    "# Encode months\n",
    "test_encode['month_sin'] = np.sin(2 * np.pi * test_encode['month_num'] / 12)\n",
    "test_encode['month_cos'] = np.cos(2 * np.pi * test_encode['month_num'] / 12)\n",
    "\n",
    "# Encode day\n",
    "test_encode['day_sin'] = np.sin(2 * np.pi * test_encode['day'] / 31)\n",
    "test_encode['day_cos'] = np.cos(2 * np.pi * test_encode['day'] / 31)\n",
    "\n",
    "# Drop \"month\" and \"day\" columns\n",
    "test_encode = test_encode.drop(columns=[\"month\",\"day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode = pd.get_dummies(test_encode, drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for class 1 (\"Yes\")\n",
    "probs = model_1.predict_proba(test_encode)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with Id and probs\n",
    "output = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'y': probs.round(1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Export to CSV\n",
    "output.to_csv('predict_1.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_2 = model_rf_1.predict_proba(test_encode)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with Id and probs\n",
    "output = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'y': probs_2.round(1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Export to CSV\n",
    "output.to_csv('predict_2.csv', index=False)\n",
    "print(\"Predictions saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mlflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (436093207.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mlflow server --host 127.0.0.1 --port 8080\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tracking uri using this\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model signature for deployment\n",
    "# signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def create_and_train_model(weight, estimator):\n",
    "\n",
    "    # Define model architecture\n",
    "    model = RandomForestClassifier(class_weight=weight, n_estimators=estimator)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"accuracy_score\": accuracy_score(y_test, y_pred),\n",
    "        \"roc_auc_score\": roc_auc_score(y_test, y_proba),\n",
    "    }\n",
    "\n",
    "# Hyperparameter Options\n",
    "class_weight_options = [None, \"balanced\", \"balanced_subsample\"]\n",
    "n_estimators_options = [10, 50, 100]\n",
    "\n",
    "# Generate all parameter combination\n",
    "param_combinations = list(product(class_weight_options, n_estimators_options))\n",
    "\n",
    "# Set MLflow experiment\n",
    "experiment_name = \"bank_model_tuning\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Starting hyperparameter optimization experiment: {experiment_name}\")\n",
    "\n",
    "# Create variables to store best roc auc score and best hyperparameters\n",
    "best_roc_auc = -1\n",
    "best_params = {}\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"hyperparameter-tune\"):\n",
    "    # Log metadata for this experiment\n",
    "    mlflow.log_params({\n",
    "        \"optimization_method\": \"manual_sweep\",\n",
    "        \"objective_metric\": \"roc_auc_score\",\n",
    "        \"model_type\": \"random_forest\",\n",
    "        \"dataset\": \"bank_kaggle\",\n",
    "        \"total_trials\": len(param_combinations),\n",
    "    })\n",
    "\n",
    "    for weight, estimator in param_combinations:\n",
    "        # Start nested run\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # Log hyperparameters for this trial\n",
    "            mlflow.log_params({\n",
    "                \"class_weight\": weight,\n",
    "                \"n_estimators\": estimator,\n",
    "            })\n",
    "\n",
    "            # Train and evaluate\n",
    "            result = create_and_train_model(weight, estimator)\n",
    "\n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                \"accuracy_score\": result[\"accuracy_score\"],\n",
    "                \"roc_auc_score\": result[\"roc_auc_score\"],\n",
    "            })\n",
    "\n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(result[\"model\"], artifact_path=\"model_rf\", signature=signature, input_example=X.iloc[[0]])\n",
    "\n",
    "            # Update best result\n",
    "            if result[\"roc_auc_score\"] > best_roc_auc:\n",
    "                best_roc_auc = result[\"roc_auc_score\"]\n",
    "                best_params = {\"class_weight\": weight, \"n_estimators\": estimator}\n",
    "\n",
    "    # Log best hyperparameters and metric\n",
    "    mlflow.log_params({\n",
    "        \"best_class_weight\": best_params[\"class_weight\"],\n",
    "        \"best_n_estimators\": best_params[\"n_estimators\"],\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        \"best_roc_auc_score\": best_roc_auc,\n",
    "        \"optimization_completed\": 1\n",
    "    })\n",
    "\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    print(\"Best ROC AUC score:\", best_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1756180716337, experiment_id='0', last_update_time=1756180716337, lifecycle_stage='active', name='Default', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "experiment_name = \"Default\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>25</td>\n",
       "      <td>aug</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>514</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>jun</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>602</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>may</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>may</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>889</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>feb</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age          job  marital  education default  balance housing loan  \\\n",
       "0   0   42   technician  married  secondary      no        7      no   no   \n",
       "1   1   38  blue-collar  married  secondary      no      514      no   no   \n",
       "2   2   36  blue-collar  married  secondary      no      602     yes   no   \n",
       "3   3   27      student   single  secondary      no       34     yes   no   \n",
       "4   4   26   technician  married  secondary      no      889     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0  cellular   25   aug       117         3     -1         0  unknown  0  \n",
       "1   unknown   18   jun       185         1     -1         0  unknown  0  \n",
       "2   unknown   14   may       111         2     -1         0  unknown  0  \n",
       "3   unknown   28   may        10         2     -1         0  unknown  0  \n",
       "4  cellular    3   feb       902         1     -1         0  unknown  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "      <th>age_group</th>\n",
       "      <th>job_group</th>\n",
       "      <th>was_contacted_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   marital  education  balance  housing  loan  contact  day  month  campaign  \\\n",
       "0        1          1        7        0     0        0   25      1         3   \n",
       "1        1          1      514        0     0        2   18      6         1   \n",
       "2        1          1      602        1     0        2   14      8         2   \n",
       "3        2          1       34        1     0        2   28      8         2   \n",
       "4        1          1      889        1     0        0    3      3         1   \n",
       "\n",
       "   pdays  previous  poutcome  y  age_group  job_group  was_contacted_before  \n",
       "0     -1         0         3  0          2          3                     0  \n",
       "1     -1         0         3  0          2          3                     0  \n",
       "2     -1         0         3  0          2          3                     0  \n",
       "3     -1         0         3  0          1          2                     0  \n",
       "4     -1         0         3  1          1          3                     0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"y\"])\n",
    "y = df[\"y\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>age_group</th>\n",
       "      <th>job_group</th>\n",
       "      <th>was_contacted_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617631</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580701</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696804</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>643</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316225</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>604</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        marital  education  balance  housing  loan  contact  day  month  \\\n",
       "6036          1          1     -254        0     0        0   25      1   \n",
       "617631        1          1      807        0     0        0    8      1   \n",
       "580701        1          1       -1        1     0        2   23      8   \n",
       "696804        2          1      643        1     0        0   11      8   \n",
       "316225        2          1      604        0     0        0   25      5   \n",
       "\n",
       "        campaign  pdays  previous  poutcome  age_group  job_group  \\\n",
       "6036           4     -1         0         3          1          3   \n",
       "617631         3     -1         0         3          1          3   \n",
       "580701         1     -1         0         3          2          3   \n",
       "696804         3     -1         0         3          0          3   \n",
       "316225         2     -1         0         3          1          3   \n",
       "\n",
       "        was_contacted_before  \n",
       "6036                       0  \n",
       "617631                     0  \n",
       "580701                     0  \n",
       "696804                     0  \n",
       "316225                     0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036      0\n",
       "617631    0\n",
       "580701    0\n",
       "696804    0\n",
       "316225    0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X_train.sample(1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>age_group</th>\n",
       "      <th>job_group</th>\n",
       "      <th>was_contacted_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117250</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        marital  education  balance  housing  loan  contact  day  month  \\\n",
       "117250        2          1      676        1     0        0    6      8   \n",
       "\n",
       "        campaign  pdays  previous  poutcome  age_group  job_group  \\\n",
       "117250         2     -1         0         3          1          3   \n",
       "\n",
       "        was_contacted_before  \n",
       "117250                     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiennguyen/anaconda3/envs/mlflow3/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "signature = mlflow.models.infer_signature(sample, model_rf.predict(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiennguyen/anaconda3/envs/mlflow3/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run model at: http://localhost:5000/#/experiments/595485855145224301/runs/ac26b88659f24fc19a26c173aaf16e43\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/595485855145224301\n"
     ]
    }
   ],
   "source": [
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Default\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=\"model\"):\n",
    "    # Fit model\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train,y_train)\n",
    "\n",
    "    # Make predicitons\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Log metrics\n",
    "    metrics = {\"roc_auc_score\": roc_auc_score(y_test,y_pred)}\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, rf.predict(X_train))\n",
    "\n",
    "    # Log the model, which inherits the parameters and metric\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_rf,\n",
    "        name=\"rf_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train[:5],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export MLFLOW_TRACKING_URI=http://localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "for rm in client.search_registered_models():\n",
    "    print(rm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serve the model in separate terminal\n",
    "# Copy the model path from artifacts rather than using models path\n",
    "# Add --env-manager=conda to avoid \"pyenv binary\"\n",
    "\n",
    "! mlflow models serve -m \"mlflow-artifacts:/0/f8f9ea96657f423b88830dc9ab68201f/artifacts/pipeline_full\" --env-manager=conda --port 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "url = \"http://127.0.0.1:5002/invocations\"\n",
    "\n",
    "payload = {\n",
    "    \"columns\": [\n",
    "        \"id\",\"age\",\"job\",\"marital\",\"education\",\"default\",\"balance\",\n",
    "        \"housing\",\"loan\",\"contact\",\"day\",\"month\",\"duration\",\n",
    "        \"campaign\",\"pdays\",\"previous\",\"poutcome\"\n",
    "    ],\n",
    "    \"data\": [\n",
    "        [6036,34,\"technician\",\"married\",\"secondary\",\"no\",-254,\n",
    "         \"no\",\"no\",\"cellular\",25,\"aug\",134,4,-1,0,\"unknown\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(payload))\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
